{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "import ssl\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "papers = pd.read_csv('Volumes/CIRCUIT_HD2/CRIMSON/Topic_Modeling_Practice/papers.csv')\n",
    "print(papers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "papers['paper_text_processed']= \\\n",
    "papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "#convert titles to lowercase\n",
    "papers['paper_text_processed']= \\\n",
    "papers['paper_text_processed'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = ','.join(list(papers['paper_text_processed'].values))\n",
    "\n",
    "wordcloud = WordCloud(background_color='white',max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#tokenization (also removing stopwords)\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','subject','re','edu','use'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield((gensim.utils.simple_preprocess(str(sentence),deacc = True)))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "            if word not in stop_words] for doc in texts]\n",
    "\n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "data_words = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "texts = data_words\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "\n",
    "#doc_lda = lda_model[corpus]\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "\n",
    "print(get_top_n(lda_model, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Page_ID', 'Topics', 'Co-Req ID', '']\n",
    "data = ['...', lda_model.print_topics(), ]\n",
    "\n",
    "filename = 'Volumes/CIRCUIT_HD2/CRIMSON/Topic_Modeling_Practice/prototype_topics.csv'\n",
    "\n",
    "with open(filename, 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write the data\n",
    "    writer.writerow(data)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
